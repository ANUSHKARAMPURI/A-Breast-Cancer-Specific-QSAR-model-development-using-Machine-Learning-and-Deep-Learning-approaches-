{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8208a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory path where the Excel files are located\n",
    "directory_path = 'D:\\combo_IC50_skew_kurt_data'  # Replace with the actual directory path\n",
    "\n",
    "# Get a list of Excel files in the specified directory\n",
    "csv_files = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the Excel files and concatenate them\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)  # Read each Excel file\n",
    "    concatenated_df = pd.concat([concatenated_df, df], ignore_index=True)\n",
    "\n",
    "# Now, 'concatenated_df' contains the combined data from all Excel files in the specified directory.\n",
    "\n",
    "# You can further process or save the concatenated DataFrame as needed.\n",
    "valid_data = pd.read_csv(r'D:\\combo_IC50_skew_kurt_data\\validation\\chunk_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2913d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a24bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = concatenated_df.drop('Combo IC50', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6385db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = concatenated_df['Combo IC50']\n",
    "Y = pd.DataFrame(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1824165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eff0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of feature selection using Random Forest feature importances\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c16932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Your data loading and model training code\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming you have already defined and split your x_train and y_train data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_leaf_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m420\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m regressor\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m     12\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     14\u001b[0m X_valid \u001b[38;5;241m=\u001b[39m valid_data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombo IC50\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time  # Import the time module\n",
    "\n",
    "# Start tracking time\n",
    "start_time = time.time()\n",
    "\n",
    "# Your data loading and model training code\n",
    "# Assuming you have already defined and split your x_train and y_train data\n",
    "regressor = RandomForestRegressor(max_depth=10, max_leaf_nodes=10, n_estimators=500, random_state=420, min_samples_split=5, min_samples_leaf=2)\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_pred = regressor.predict(X_test)\n",
    "   \n",
    "    \n",
    "X_valid = valid_data.drop('Combo IC50', axis=1)\n",
    "Y_valid = valid_data['Combo IC50']\n",
    "Y_valid_pred = regressor.predict(X_valid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dff042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "# Calculate performance metrics\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "rmse_valid = np.sqrt(mean_squared_error(Y_valid, Y_valid_pred))\n",
    "r2_valid = r2_score(Y_valid, Y_valid_pred)\n",
    "\n",
    "# End tracking time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the total time taken\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the results and time taken\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Root Mean Squared Error (validation set):\", rmse_valid)\n",
    "print(\"R-squared (validation set):\", r2_valid)\n",
    "print(\"Total Time Taken:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95b5d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "evs = explained_variance_score(Y_test, Y_pred)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "\n",
    "# for validation set\n",
    "import numpy as np\n",
    "mse = mean_squared_error(Y_valid, Y_valid_pred)\n",
    "print(\"Mean Squared Error (validation set):\", mse)\n",
    "rmse = np.sqrt(mean_squared_error(Y_valid, Y_valid_pred))\n",
    "print(\"Root Mean Squared Error (validation set):\", rmse)\n",
    "mae = mean_absolute_error(Y_valid, Y_valid_pred)\n",
    "print(\"Mean Absolute Error (validation set):\", mae)\n",
    "r2 = r2_score(Y_valid, Y_valid_pred)\n",
    "print(\"R-squared (validation set):\", r2)\n",
    "evs = explained_variance_score(Y_valid, Y_valid_pred)\n",
    "print(\"Explained Variance Score (validation set):\", evs)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, Y, cv=8)  # 5-fold cross-validation\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Create a scatterplot with regression line and confidence interval\n",
    "plt.figure(figsize=(25, 20))  # Adjust the figure size as needed\n",
    "sns.regplot(x=Y_test, y=Y_pred, scatter_kws={'s': 15}, ci=95)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Actual Values\", fontsize=30)\n",
    "plt.ylabel(\"Predicted Values\", fontsize=30)\n",
    "plt.title(\"Combo IC50 Regression Plot\", fontsize=30)\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# residual plot\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = np.ravel(Y_test)\n",
    "Y_pred\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = Y_test - Y_pred\n",
    "residuals = pd.DataFrame(residuals)\n",
    "residuals = np.ravel(residuals)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and residuals 'residuals'\n",
    "# Replace 'y_pred' and 'residuals' with your actual data\n",
    "\n",
    "# Check the dimensions of 'y_pred' and 'residuals'\n",
    "print(len(Y_pred), len(residuals))\n",
    "\n",
    "# Create a residual plot\n",
    "plt.figure(figsize=(30, 20))  # Adjust the figure size as needed\n",
    "\n",
    "# Specify the color for the residual points (e.g., 'lightcoral')\n",
    "sns.residplot(x=Y_pred, y=residuals, scatter_kws={'s': 8, 'color': 'purple'})\n",
    "\n",
    "plt.xticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "plt.yticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "\n",
    "# Add labels and a title with increased font size\n",
    "plt.xlabel(\"Predicted Values\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Residuals\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.title(\" Combo IC50 Residual plot\", fontsize=30)  # Adjust fontsize as needed\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# validation data plots\n",
    "\n",
    "# plots for validation set\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Create a scatterplot with regression line and confidence interval\n",
    "plt.figure(figsize=(25, 20))  # Adjust the figure size as needed\n",
    "sns.regplot(x=Y_valid, y=Y_valid_pred, scatter_kws={'s': 15}, ci=95)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Actual Values\", fontsize=30)\n",
    "plt.ylabel(\"Predicted Values\", fontsize=30)\n",
    "plt.title(\"Combo IC50 Regression Plot (validation set)\", fontsize=30)\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# residual plot\n",
    "\n",
    "Y_valid = np.array(Y_valid)\n",
    "Y_valid = np.ravel(Y_valid)\n",
    "Y_valid_pred\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = Y_valid - Y_valid_pred\n",
    "residuals = pd.DataFrame(residuals)\n",
    "residuals = np.ravel(residuals)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and residuals 'residuals'\n",
    "# Replace 'y_pred' and 'residuals' with your actual data\n",
    "\n",
    "# Check the dimensions of 'y_pred' and 'residuals'\n",
    "print(len(Y_valid_pred), len(residuals))\n",
    "\n",
    "# Create a residual plot\n",
    "plt.figure(figsize=(30, 20))  # Adjust the figure size as needed\n",
    "\n",
    "# Specify the color for the residual points (e.g., 'lightcoral')\n",
    "sns.residplot(x=Y_valid_pred, y=residuals, scatter_kws={'s': 8, 'color': 'purple'})\n",
    "\n",
    "plt.xticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "plt.yticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "\n",
    "# Add labels and a title with increased font size\n",
    "plt.xlabel(\"Predicted Values\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Residuals\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.title(\" Combo IC50 Residual plot (validation set)\", fontsize=30)  # Adjust fontsize as needed\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28beb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8f647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14223d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfe03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5985c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98322f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f6a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53699ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6951541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38675d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96adea06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf4d313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have already defined and split your x_train and y_train data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m regressor \u001b[38;5;241m=\u001b[39m RandomForestRegressor(max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, max_leaf_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m402\u001b[39m, min_samples_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, min_samples_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m regressor\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m      4\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m X_valid \u001b[38;5;241m=\u001b[39m valid_data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombo IC50\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming you have already defined and split your x_train and y_train data\n",
    "regressor = RandomForestRegressor(max_depth = 10, max_leaf_nodes = 10, n_estimators=100, random_state=402, min_samples_split = 5, min_samples_leaf = 2)\n",
    "regressor.fit(X_train, Y_train)\n",
    "Y_pred = regressor.predict(X_test)\n",
    "\n",
    "X_valid = valid_data.drop('Combo IC50', axis = 1)\n",
    "Y_valid = valid_data['Combo IC50']\n",
    "Y_valid_pred = regressor.predict(X_valid)\n",
    "\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_valid, Y_valid_pred))\n",
    "print(\"Root Mean Squared Error (validation set):\", rmse)\n",
    "r2 = r2_score(Y_valid, Y_valid_pred)\n",
    "print(\"R-squared (validation set):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5907778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],      # Different numbers of trees\n",
    "    'max_depth': [5, 10, 15],            # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],     # Minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]        # Minimum samples required for a leaf node\n",
    "}\n",
    "\n",
    "# Create the RandomForestRegressor\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16532d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "X_valid = valid_data.drop('Combo IC50', axis = 1)\n",
    "Y_valid = valid_data['Combo IC50']\n",
    "\n",
    "\n",
    "Y_valid_pred = best_model.predict(X_valid)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "evs = explained_variance_score(Y_test, Y_pred)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "\n",
    "# for validation set\n",
    "import numpy as np\n",
    "mse = mean_squared_error(Y_valid, Y_valid_pred)\n",
    "print(\"Mean Squared Error (validation set):\", mse)\n",
    "rmse = np.sqrt(mean_squared_error(Y_valid, Y_valid_pred))\n",
    "print(\"Root Mean Squared Error (validation set):\", rmse)\n",
    "mae = mean_absolute_error(Y_valid, Y_valid_pred)\n",
    "print(\"Mean Absolute Error (validation set):\", mae)\n",
    "r2 = r2_score(Y_valid, Y_valid_pred)\n",
    "print(\"R-squared (validation set):\", r2)\n",
    "evs = explained_variance_score(Y_valid, Y_valid_pred)\n",
    "print(\"Explained Variance Score (validation set):\", evs)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, Y, cv=8)  # 5-fold cross-validation\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Create a scatterplot with regression line and confidence interval\n",
    "plt.figure(figsize=(25, 20))  # Adjust the figure size as needed\n",
    "sns.regplot(x=Y_test, y=Y_pred, scatter_kws={'s': 15}, ci=95)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Actual Values\", fontsize=30)\n",
    "plt.ylabel(\"Predicted Values\", fontsize=30)\n",
    "plt.title(\"Combo IC50 Regression Plot\", fontsize=30)\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# residual plot\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = np.ravel(Y_test)\n",
    "Y_pred\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = Y_test - Y_pred\n",
    "residuals = pd.DataFrame(residuals)\n",
    "residuals = np.ravel(residuals)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and residuals 'residuals'\n",
    "# Replace 'y_pred' and 'residuals' with your actual data\n",
    "\n",
    "# Check the dimensions of 'y_pred' and 'residuals'\n",
    "print(len(Y_pred), len(residuals))\n",
    "\n",
    "# Create a residual plot\n",
    "plt.figure(figsize=(30, 20))  # Adjust the figure size as needed\n",
    "\n",
    "# Specify the color for the residual points (e.g., 'lightcoral')\n",
    "sns.residplot(x=Y_pred, y=residuals, scatter_kws={'s': 8, 'color': 'purple'})\n",
    "\n",
    "plt.xticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "plt.yticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "\n",
    "# Add labels and a title with increased font size\n",
    "plt.xlabel(\"Predicted Values\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Residuals\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.title(\" Combo IC50 Residual plot\", fontsize=30)  # Adjust fontsize as needed\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# validation data plots\n",
    "\n",
    "# plots for validation set\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Create a scatterplot with regression line and confidence interval\n",
    "plt.figure(figsize=(25, 20))  # Adjust the figure size as needed\n",
    "sns.regplot(x=Y_valid, y=Y_valid_pred, scatter_kws={'s': 15}, ci=95)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Actual Values\", fontsize=30)\n",
    "plt.ylabel(\"Predicted Values\", fontsize=30)\n",
    "plt.title(\"Combo IC50 Regression Plot (validation set)\", fontsize=30)\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# residual plot\n",
    "\n",
    "Y_valid = np.array(Y_valid)\n",
    "Y_valid = np.ravel(Y_valid)\n",
    "Y_valid_pred\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = Y_valid - Y_valid_pred\n",
    "residuals = pd.DataFrame(residuals)\n",
    "residuals = np.ravel(residuals)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and residuals 'residuals'\n",
    "# Replace 'y_pred' and 'residuals' with your actual data\n",
    "\n",
    "# Check the dimensions of 'y_pred' and 'residuals'\n",
    "print(len(Y_valid_pred), len(residuals))\n",
    "\n",
    "# Create a residual plot\n",
    "plt.figure(figsize=(30, 20))  # Adjust the figure size as needed\n",
    "\n",
    "# Specify the color for the residual points (e.g., 'lightcoral')\n",
    "sns.residplot(x=Y_valid_pred, y=residuals, scatter_kws={'s': 8, 'color': 'purple'})\n",
    "\n",
    "plt.xticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "plt.yticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "\n",
    "# Add labels and a title with increased font size\n",
    "plt.xlabel(\"Predicted Values\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Residuals\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.title(\" Combo IC50 Residual plot (validation set)\", fontsize=30)  # Adjust fontsize as needed\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42944f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04422ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ef17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84a6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b30b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d5f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ab3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61623415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, x, y, cv=8)  # 5-fold cross-validation\n",
    "print(\"Cross-Validation Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8428e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Create a scatterplot with regression line and confidence interval\n",
    "plt.figure(figsize=(25, 20))  # Adjust the figure size as needed\n",
    "sns.regplot(x=y_test, y=y_pred, scatter_kws={'s': 15}, ci=95)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Actual Values\", fontsize=30)\n",
    "plt.ylabel(\"Predicted Values\", fontsize=30)\n",
    "plt.title(\"Combo IC50 Regression Plot - test set\", fontsize=30)\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3932c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "y_test = np.ravel(y_test)\n",
    "y_pred = np.ravel(y_pred)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "residuals = pd.DataFrame(residuals)\n",
    "residuals = np.ravel(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e05f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9478be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and residuals 'residuals'\n",
    "# Replace 'y_pred' and 'residuals' with your actual data\n",
    "\n",
    "# Check the dimensions of 'y_pred' and 'residuals'\n",
    "print(len(y_pred), len(residuals))\n",
    "\n",
    "# Create a residual plot\n",
    "plt.figure(figsize=(30, 20))  # Adjust the figure size as needed\n",
    "\n",
    "# Specify the color for the residual points (e.g., 'lightcoral')\n",
    "sns.residplot(x=y_pred, y=residuals, scatter_kws={'s': 8, 'color': 'purple'})\n",
    "\n",
    "plt.xticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "plt.yticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "\n",
    "# Add labels and a title with increased font size\n",
    "plt.xlabel(\"Predicted Values\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Residuals\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.title(\"Residual Plot for Combo IC50_Test-set\", fontsize=26)  # Adjust fontsize as needed\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5129cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(r'D:\\encoded_std_merged_data\\validation set\\chunk_150000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57735899",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = val.drop('Combo IC50', axis = 1)\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74020e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = val['Combo IC50']\n",
    "y_val = pd.DataFrame(y_val)\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "y_pred_val = regressor.predict(x_val)\n",
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc730d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.array(y_val)\n",
    "y_val = np.ravel(y_val)\n",
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf735a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Create a scatterplot with regression line and confidence interval\n",
    "plt.figure(figsize=(25, 20))  # Adjust the figure size as needed\n",
    "sns.regplot(x=y_val, y=y_pred_val, scatter_kws={'s': 15}, ci=95)\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel(\"Actual Values\", fontsize=30)\n",
    "plt.ylabel(\"Predicted Values\", fontsize=30)\n",
    "plt.title(\" Combo IC50 Regression Plot - Validation set\", fontsize=30)\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c25a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_val, y_pred_val)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "mae = mean_absolute_error(y_val, y_pred_val)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "r2 = r2_score(y_val, y_pred_val)\n",
    "print(\"R-squared:\", r2)\n",
    "evs = explained_variance_score(y_val, y_pred_val)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, x_val, y_val, cv=8)  # 5-fold cross-validation\n",
    "print(\"Cross-Validation Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and actual values 'y_true'\n",
    "# Replace 'y_pred' and 'y_true' with your actual data\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_val - y_pred_val\n",
    "residuals = pd.DataFrame(residuals)\n",
    "residuals = np.ravel(residuals)\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "y_pred_val = np.array(y_pred_val)\n",
    "y_pred_val = np.ravel(y_pred_val)\n",
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065112d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your predicted values 'y_pred' and residuals 'residuals'\n",
    "# Replace 'y_pred' and 'residuals' with your actual data\n",
    "\n",
    "# Check the dimensions of 'y_pred' and 'residuals'\n",
    "print(len(y_pred_val), len(residuals))\n",
    "\n",
    "# Create a residual plot\n",
    "plt.figure(figsize=(30, 20))  # Adjust the figure size as needed\n",
    "\n",
    "# Specify the color for the residual points (e.g., 'lightcoral')\n",
    "sns.residplot(x=y_pred_val, y=residuals, scatter_kws={'s': 8, 'color': 'purple'})\n",
    "\n",
    "plt.xticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "plt.yticks(fontsize=18)  # Adjust the fontsize as needed\n",
    "\n",
    "# Add labels and a title with increased font size\n",
    "plt.xlabel(\"Predicted Values\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Residuals\", fontsize=24)  # Adjust fontsize as needed\n",
    "plt.title(\"Residual Plot for Combo IC50_valid set\", fontsize=26)  # Adjust fontsize as needed\n",
    "\n",
    "# Show the grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e770ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dad0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
