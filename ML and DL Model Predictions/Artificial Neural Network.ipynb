{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66fda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory path where the Excel files are located\n",
    "directory_path = 'D:\\combo_IC50_skew_kurt_data'  # Replace with the actual directory path\n",
    "\n",
    "# Get a list of Excel files in the specified directory\n",
    "csv_files = [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Loop through the Excel files and concatenate them\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)  # Read each Excel file\n",
    "    concatenated_df = pd.concat([concatenated_df, df], ignore_index=True)\n",
    "\n",
    "# Now, 'concatenated_df' contains the combined data from all Excel files in the specified directory.\n",
    "\n",
    "# You can further process or save the concatenated DataFrame as needed.\n",
    "valid_data = pd.read_csv(r'D:\\combo_IC50_skew_kurt_data\\validation\\chunk_14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39f026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a8cf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = concatenated_df.drop('Combo IC50', axis = 1)\n",
    "Y = concatenated_df['Combo IC50']\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "X_valid = valid_data.drop('Combo IC50', axis = 1)\n",
    "Y_valid = valid_data['Combo IC50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535a229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b716687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12a35b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell Line name</th>\n",
       "      <th>SDIM</th>\n",
       "      <th>Tissue</th>\n",
       "      <th>Cancer Type</th>\n",
       "      <th>Anchor Name</th>\n",
       "      <th>Anchor Target</th>\n",
       "      <th>Anchor Pathway</th>\n",
       "      <th>Anchor Conc</th>\n",
       "      <th>Library Name</th>\n",
       "      <th>library Target</th>\n",
       "      <th>...</th>\n",
       "      <th>TDB2m.1</th>\n",
       "      <th>TDB3i.1_y</th>\n",
       "      <th>GRAVH-3</th>\n",
       "      <th>TDB2m.2</th>\n",
       "      <th>TDB7e</th>\n",
       "      <th>TDB5v.1</th>\n",
       "      <th>TDB3v_y</th>\n",
       "      <th>TDB4e.1</th>\n",
       "      <th>TDB5m.2_y</th>\n",
       "      <th>TDB4p.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.0</td>\n",
       "      <td>143612.0</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "      <td>143612.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.999422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>0.999634</td>\n",
       "      <td>1.000099</td>\n",
       "      <td>1.000235</td>\n",
       "      <td>1.000063</td>\n",
       "      <td>1.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>0.999271</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.999484</td>\n",
       "      <td>0.998809</td>\n",
       "      <td>0.999179</td>\n",
       "      <td>0.999015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.315904</td>\n",
       "      <td>-2.315904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.542733</td>\n",
       "      <td>-2.542733</td>\n",
       "      <td>-2.172609</td>\n",
       "      <td>-1.304740</td>\n",
       "      <td>-2.705830</td>\n",
       "      <td>-2.787943</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.210173</td>\n",
       "      <td>-1.595415</td>\n",
       "      <td>-3.733669</td>\n",
       "      <td>-2.210173</td>\n",
       "      <td>-4.177947</td>\n",
       "      <td>-3.297701</td>\n",
       "      <td>-2.936170</td>\n",
       "      <td>-2.483399</td>\n",
       "      <td>-2.006142</td>\n",
       "      <td>-3.274524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.875876</td>\n",
       "      <td>-0.875876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.569346</td>\n",
       "      <td>-0.569346</td>\n",
       "      <td>-0.226899</td>\n",
       "      <td>-1.032556</td>\n",
       "      <td>-0.704916</td>\n",
       "      <td>-0.640981</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693462</td>\n",
       "      <td>-0.659735</td>\n",
       "      <td>-0.349028</td>\n",
       "      <td>-0.693462</td>\n",
       "      <td>-0.639410</td>\n",
       "      <td>-0.590462</td>\n",
       "      <td>-0.548243</td>\n",
       "      <td>-0.671694</td>\n",
       "      <td>-0.701527</td>\n",
       "      <td>-0.477859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.056554</td>\n",
       "      <td>0.056554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129245</td>\n",
       "      <td>0.129245</td>\n",
       "      <td>0.210389</td>\n",
       "      <td>0.038221</td>\n",
       "      <td>0.182240</td>\n",
       "      <td>0.184391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193020</td>\n",
       "      <td>-0.136856</td>\n",
       "      <td>0.021432</td>\n",
       "      <td>-0.193020</td>\n",
       "      <td>-0.018621</td>\n",
       "      <td>-0.223286</td>\n",
       "      <td>-0.185623</td>\n",
       "      <td>0.092671</td>\n",
       "      <td>-0.107921</td>\n",
       "      <td>-0.120832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.904095</td>\n",
       "      <td>0.904095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778971</td>\n",
       "      <td>0.778971</td>\n",
       "      <td>0.745955</td>\n",
       "      <td>0.759422</td>\n",
       "      <td>0.854822</td>\n",
       "      <td>0.825933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566148</td>\n",
       "      <td>0.369048</td>\n",
       "      <td>0.547891</td>\n",
       "      <td>0.566148</td>\n",
       "      <td>0.440661</td>\n",
       "      <td>0.707064</td>\n",
       "      <td>0.670609</td>\n",
       "      <td>0.695597</td>\n",
       "      <td>0.476903</td>\n",
       "      <td>0.405116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.571027</td>\n",
       "      <td>1.571027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.320941</td>\n",
       "      <td>1.320941</td>\n",
       "      <td>1.197459</td>\n",
       "      <td>2.009367</td>\n",
       "      <td>1.378518</td>\n",
       "      <td>1.415572</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947178</td>\n",
       "      <td>3.657047</td>\n",
       "      <td>2.361710</td>\n",
       "      <td>1.947178</td>\n",
       "      <td>1.944347</td>\n",
       "      <td>2.305586</td>\n",
       "      <td>2.456782</td>\n",
       "      <td>2.684624</td>\n",
       "      <td>2.485777</td>\n",
       "      <td>2.322941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cell Line name           SDIM    Tissue  Cancer Type    Anchor Name  \\\n",
       "count   143612.000000  143612.000000  143612.0     143612.0  143612.000000   \n",
       "mean         0.001149       0.001149       0.0          0.0      -0.000021   \n",
       "std          0.999422       0.999422       0.0          0.0       0.999634   \n",
       "min         -2.315904      -2.315904       0.0          0.0      -2.542733   \n",
       "25%         -0.875876      -0.875876       0.0          0.0      -0.569346   \n",
       "50%          0.056554       0.056554       0.0          0.0       0.129245   \n",
       "75%          0.904095       0.904095       0.0          0.0       0.778971   \n",
       "max          1.571027       1.571027       0.0          0.0       1.320941   \n",
       "\n",
       "       Anchor Target  Anchor Pathway    Anchor Conc   Library Name  \\\n",
       "count  143612.000000   143612.000000  143612.000000  143612.000000   \n",
       "mean       -0.000021       -0.000567       0.000568      -0.000149   \n",
       "std         0.999634        1.000099       1.000235       1.000063   \n",
       "min        -2.542733       -2.172609      -1.304740      -2.705830   \n",
       "25%        -0.569346       -0.226899      -1.032556      -0.704916   \n",
       "50%         0.129245        0.210389       0.038221       0.182240   \n",
       "75%         0.778971        0.745955       0.759422       0.854822   \n",
       "max         1.320941        1.197459       2.009367       1.378518   \n",
       "\n",
       "       library Target  ...        TDB2m.1      TDB3i.1_y        GRAVH-3  \\\n",
       "count   143612.000000  ...  143612.000000  143612.000000  143612.000000   \n",
       "mean        -0.000046  ...       0.000586       0.000011       0.000069   \n",
       "std          1.000070  ...       0.999271       0.999776       0.999544   \n",
       "min         -2.787943  ...      -2.210173      -1.595415      -3.733669   \n",
       "25%         -0.640981  ...      -0.693462      -0.659735      -0.349028   \n",
       "50%          0.184391  ...      -0.193020      -0.136856       0.021432   \n",
       "75%          0.825933  ...       0.566148       0.369048       0.547891   \n",
       "max          1.415572  ...       1.947178       3.657047       2.361710   \n",
       "\n",
       "             TDB2m.2          TDB7e        TDB5v.1        TDB3v_y  \\\n",
       "count  143612.000000  143612.000000  143612.000000  143612.000000   \n",
       "mean        0.000586       0.001604       0.001113       0.000649   \n",
       "std         0.999271       0.999357       0.998970       0.999484   \n",
       "min        -2.210173      -4.177947      -3.297701      -2.936170   \n",
       "25%        -0.693462      -0.639410      -0.590462      -0.548243   \n",
       "50%        -0.193020      -0.018621      -0.223286      -0.185623   \n",
       "75%         0.566148       0.440661       0.707064       0.670609   \n",
       "max         1.947178       1.944347       2.305586       2.456782   \n",
       "\n",
       "             TDB4e.1      TDB5m.2_y        TDB4p.1  \n",
       "count  143612.000000  143612.000000  143612.000000  \n",
       "mean        0.000881       0.000841       0.000382  \n",
       "std         0.998809       0.999179       0.999015  \n",
       "min        -2.483399      -2.006142      -3.274524  \n",
       "25%        -0.671694      -0.701527      -0.477859  \n",
       "50%         0.092671      -0.107921      -0.120832  \n",
       "75%         0.695597       0.476903       0.405116  \n",
       "max         2.684624       2.485777       2.322941  \n",
       "\n",
       "[8 rows x 2516 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0708e9ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "377/377 [==============================] - 192s 510ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      " 16/377 [>.............................] - ETA: 2:40 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     46\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[1;32m---> 48\u001b[0m training_history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     49\u001b[0m     X_train, Y_train,\n\u001b[0;32m     50\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m     51\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     52\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m,\n\u001b[0;32m     53\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     54\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     55\u001b[0m         EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     56\u001b[0m         lr_callback\n\u001b[0;32m     57\u001b[0m     ]\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     62\u001b[0m mse \u001b[38;5;241m=\u001b[39m ANN\u001b[38;5;241m.\u001b[39mevaluate(X_test, Y_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "# Load your dataset and preprocess it if necessary (X and Y should be defined)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=2230)\n",
    "\n",
    "# Define the neural network model\n",
    "ANN = Sequential()\n",
    "ANN.add(Dense(2516, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "ANN.add(Dropout(0.25))  # Dropout layer to prevent overfitting\n",
    "ANN.add(Dense(500, activation='relu'))\n",
    "ANN.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.001  # You can adjust this value as needed\n",
    "\n",
    "# Compile the model with the specified learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "ANN.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Create a list to store training history for plotting\n",
    "history = []\n",
    "\n",
    "# Define a custom callback to track learning rate during training\n",
    "class LearningRateCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        history.append(model.optimizer.lr.numpy())\n",
    "\n",
    "# Create an instance of the custom callback\n",
    "lr_callback = LearningRateCallback()\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "training_history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.25,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        lr_callback\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse = ANN.evaluate(X_test, Y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred = ANN.predict(X_test)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "Y_Valid_pred = ANN.predict(X_Valid)\n",
    "\n",
    "\n",
    "r_squared = r2_score(Y_test, Y_pred)\n",
    "print(f'R-squared (R²): {r_squared}')\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "evs = explained_variance_score(Y_test, Y_pred)\n",
    "print(\"Explained Variance Score:\", evs)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, X, Y, cv=8)  # 5-fold cross-validation\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "\n",
    "\n",
    "r_squared = r2_score(Y_Valid, Y_Valid_pred)\n",
    "print(f'R-squared validation set (R²): {r_squared}')\n",
    "rmse = np.sqrt(mean_squared_error(Y_Valid, Y_Valid_pred))\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "\n",
    "# Plot Loss vs. Epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(training_history.history['loss'], label='Training Loss')\n",
    "plt.plot(training_history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Learning Rate Schedule\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history, label='Learning Rate', marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot Validation Loss vs. Training Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(training_history.history['loss'], label='Training Loss')\n",
    "plt.plot(training_history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss vs. Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a regression plot with a regression line\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.regplot(x=Y_test, y=Y_pred, scatter_kws={'s': 2}, line_kws={'color': 'red'})\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title('Regression Plot - test set')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a residual plot \n",
    "residuals = Y_test - Y_pred\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.scatter(Y_test, residuals, color='red', alpha=0.9, s=2)\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title('Residual Plot - test set')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "pred_df = pd.DataFrame({\"Actual\":Y_test,\"Prediction\":Y_pred})\n",
    "pred_df.plot(kind=\"kde\")\n",
    "plt.show()\n",
    "\n",
    "pred_df.plot(kind=\"hist\")\n",
    "plt.show()\n",
    "\n",
    "# Create a regression plot with a regression line (VALIDATION SET)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.regplot(x=Y_Valid, y=Y_Valid_pred, scatter_kws={'s': 2}, line_kws={'color': 'red'})\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title('Regression Plot - validation set')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a residual plot (VALIDATION SET)\n",
    "residuals = Y_Valid - Y_Valid_pred\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.scatter(Y_Valid, residuals, color='red', alpha=0.9, s=2)\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.title('Residual Plot - validation set')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "Val_pred_df = pd.DataFrame({\"Actual\":Y_Valid,\"Prediction\":Y_Valid_pred})\n",
    "Val_pred_df.plot(kind=\"kde\")\n",
    "plt.show()\n",
    "\n",
    "Val_pred_df.plot(kind=\"hist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4758b1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
